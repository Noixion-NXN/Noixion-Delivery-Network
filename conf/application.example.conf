# Noixion Storage configuration
# ~~~~~

play.filters.hosts {
  # Allow requests to example.com, its subdomains, and localhost:9000.
  allowed = ["."]
}

# Registration kad_key (use this kad_key to protect your network)
registration.kad_key = "changeme"

# FFMPEG
ffmpeg.ffmpeg.path = "/ffmpeg/bin/ffmpeg"
ffmpeg.ffprobe.path = "/ffmpeg/bin/ffprobe"

# Secret kad_key
# ~~~~~
# The secret kad_key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same kad_key!
play.crypto.secret="changeme"

# The application languages
# ~~~~~
play.i18n.langs = [ "en", "de", "pl", "fr", "es", "ja", "ru", "zh" ]

# Internal H2 database for cache and status

db.default.driver=org.h2.Driver
db.default.url="jdbc:h2:~\\h2NoixionStorage\\default;INIT=CREATE SCHEMA IF NOT EXISTS VIEWER;DB_CLOSE_DELAY=-1;MODE=MySQL;MV_STORE=FALSE;AUTO_SERVER=TRUE"

# Ebean configuration

ebean.default="models.*"

# HTTP filters

play.filters.enabled += "play.filters.csrf.CSRFFilter"

# Max size for regular upload

play.http.parser.maxDiskBuffer = 2GB

parsers.anyContent.maxLength = 2GB

# Storage path, blank to use $HOME path
storage.path = ""

# Processing capacities separarated by commas (240p, 360p, 480p, 720p, 1080p, 2160p)
storage.resolutions = "1080p,720p,480p,360p,240p"

# Processing thread limitations (each video processing consumes 1 thread)
storage.threads.limit = 8

# MP4 preset (ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow)
storage.mp4.preset = "medium"

# Cache configuration (number of chunks)
storage.cache.size = 1024

# Chunk storage configuration
# ~~~~~
# Choose 'kademlia' for DHT storage.
# Choose 's3' to use Amazon S3 storage.
# Choose 'ipfs' to use IPFS (Inter-Planetary file system)
# Choose 'btfs' to use BTFS (BitTorrent file system)
#

storage.mode = "kademlia"

# S3 configuration

s3.bucket = "noixion-storage"
s3.region = "eu-central-1"

# S3 batch configuration

s3.batch.enabled = false
s3.batch.job.definition = ""
s3.batch.job.queue = ""
s3.batch.auth.id = ""
s3.batch.auth.key = ""

# IPFS configuration

ipfs.address = "/ip4/127.0.0.1/tcp/5001"

# BTFS configuration

btfs.api.server = "http://localhost:5001"
btfs.gateway.server = "http://localhost:8080"

# IPFS mapping database configuration (also required for BTFS)
# ----
# This database is required to map Block to IPFS file and encrypt / decrypt it.
# All servers of the network must share this database for this to work

db.ipfs.driver=com.mysql.jdbc.Driver
db.ipfs.url="jdbc:mysql://localhost/ipfs"
db.ipfs.username=playdbuser
db.ipfs.password="a strong password"


# Kademlia configuration

# Public IP and PORT for this node
kademlia.local.address = "252.28.53.11"
kademlia.local.port = 7800

# Bind address for the UDP and TCP sockets
kademlia.server.address = ""
kademlia.server.port = 7800

# Seed nodes to connect
kademlia.seed.nodes = []

# Time interval for publishing the DHT to other peers. Less time for more availability if the nodes go down frecuentlly.
kademlia.restore.interval = 600000

# Response and operation timeouts
kademlia.response.timeout = 2000
kademlia.operation.timeout = 2000

# Kademlia bucket length
kademlia.k = 5

# Kademlia backup nodes cache length in routing table
kademlia.rcache.size = 3

# Number of stale levels for considering a node offline
kademlia.stale = 1

# Max level of concurrency in operations
kademlia.concurrency = 10

# Max block size
kademlia.block.size = 5MB

# Replication factor, allways less than K
kademlia.replication = 2
